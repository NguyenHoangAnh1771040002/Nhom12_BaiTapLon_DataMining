# ğŸ“‹ DANH SÃCH CÃ”NG VIá»†C - Dá»° ÃN Dá»° ÄOÃN HUá»¶ Äáº¶T PHÃ’NG

> **Äá» tÃ i:** Dá»± Ä‘oÃ¡n huá»· Ä‘áº·t phÃ²ng khÃ¡ch sáº¡n
> **Dataset:** [Hotel Booking Demand - Kaggle](https://www.kaggle.com/datasets/jessemostipak/hotel-booking-demand)  
> **NhÃ³m:** 12  

---

## ğŸ”´ PHASE 1: THIáº¾T Láº¬P Dá»° ÃN

### 1.1. Táº¡o cáº¥u trÃºc thÆ° má»¥c
- [x] Táº¡o thÆ° má»¥c `configs/`
- [x] Táº¡o thÆ° má»¥c `data/processed/`
- [x] Táº¡o thÆ° má»¥c `notebooks/`
- [x] Táº¡o thÆ° má»¥c `src/` vá»›i cÃ¡c submodule:
  - [x] `src/data/`
  - [x] `src/features/`
  - [x] `src/mining/`
  - [x] `src/models/`
  - [x] `src/evaluation/`
  - [x] `src/visualization/`
- [x] Táº¡o thÆ° má»¥c `scripts/`
- [x] Táº¡o thÆ° má»¥c `outputs/` (figures, tables, models, reports)

### 1.2. Táº¡o cÃ¡c file cáº¥u hÃ¬nh
- [x] Táº¡o `README.md` - MÃ´ táº£ dá»± Ã¡n, hÆ°á»›ng dáº«n cÃ i Ä‘áº·t vÃ  cháº¡y
- [x] Táº¡o `requirements.txt` - Danh sÃ¡ch thÆ° viá»‡n cáº§n thiáº¿t
- [x] Táº¡o `.gitignore` - Loáº¡i trá»« data lá»›n, cache, outputs
- [x] Táº¡o `configs/params.yaml` - Tham sá»‘: seed, split ratio, paths, hyperparams
- [x] Táº¡o `src/__init__.py` vÃ  cÃ¡c `__init__.py` cho submodules
- [x] Táº¡o `outputs/` subfolders (figures, tables, models, reports)

### 1.3. Chuáº©n bá»‹ dá»¯ liá»‡u
- [x] Táº£i dataset tá»« Kaggle (náº¿u chÆ°a cÃ³)
- [x] Äáº·t file `hotel_bookings.csv` vÃ o `data/raw/`
- [x] Kiá»ƒm tra file cÃ³ Ä‘á»c Ä‘Æ°á»£c khÃ´ng

---

## ğŸŸ  PHASE 2: KHÃM PHÃ Dá»® LIá»†U (EDA)

### 2.1. Táº¡o module loader
- [x] `src/data/__init__.py`
- [x] `src/data/loader.py` - HÃ m Ä‘á»c dá»¯ liá»‡u, kiá»ƒm tra schema

### 2.2. Notebook 01_eda.ipynb âœ…
- [x] Táº¡o notebook `notebooks/01_eda.ipynb`
- [x] **Thá»‘ng kÃª tá»•ng quan:**
  - [x] Shape, dtypes, memory usage
  - [x] Sá»‘ lÆ°á»£ng missing values má»—i cá»™t
  - [x] Thá»‘ng kÃª mÃ´ táº£ (describe)
- [x] **Data Dictionary:**
  - [x] Giáº£i thÃ­ch Ã½ nghÄ©a tá»«ng cá»™t
  - [x] XÃ¡c Ä‘á»‹nh biáº¿n target: `is_canceled`
  - [x] PhÃ¢n loáº¡i: numerical vs categorical
- [x] **PhÃ¢n tÃ­ch phÃ¢n phá»‘i:**
  - [x] Biá»ƒu Ä‘á»“ 1: PhÃ¢n phá»‘i target (is_canceled) - Kiá»ƒm tra imbalance
  - [x] Biá»ƒu Ä‘á»“ 2: PhÃ¢n phá»‘i lead_time
  - [x] Biá»ƒu Ä‘á»“ 3: Tá»· lá»‡ huá»· theo hotel type
  - [x] Biá»ƒu Ä‘á»“ 4: Tá»· lá»‡ huá»· theo thÃ¡ng/mÃ¹a
  - [x] Biá»ƒu Ä‘á»“ 5: Tá»· lá»‡ huá»· theo market_segment
  - [x] Biá»ƒu Ä‘á»“ 6: Tá»· lá»‡ huá»· theo country (top 10)
- [x] **PhÃ¢n tÃ­ch tÆ°Æ¡ng quan:**
  - [x] Correlation matrix cho numerical features
  - [x] Chi-square test cho categorical vs target
- [x] **PhÃ¡t hiá»‡n váº¥n Ä‘á»:**
  - [x] XÃ¡c Ä‘á»‹nh cÃ¡c cá»™t cÃ³ DATA LEAKAGE (reservation_status, etc.)
  - [x] XÃ¡c Ä‘á»‹nh outliers
  - [x] XÃ¡c Ä‘á»‹nh cÃ¡c cá»™t cáº§n drop/transform

### Output figures
- `target_distribution.png`, `missing_values.png`
- `hotel_type_cancellation.png`, `lead_time_analysis.png`
- `cancellation_by_deposit.png`, `cancellation_by_segment.png`
- `monthly_trend.png`, `leakage_detection.png`
- `correlation_matrix.png`, `chi_square_results.png`

---

## ğŸŸ¡ PHASE 3: TIá»€N Xá»¬ LÃ & FEATURE ENGINEERING

### 3.1. Táº¡o module cleaner âœ…
- [x] `src/data/cleaner.py`
  - [x] HÃ m xá»­ lÃ½ missing values (`handle_missing_values()`)
  - [x] HÃ m xá»­ lÃ½ outliers (`handle_outliers()`, `handle_adr_outliers()`)
  - [x] HÃ m loáº¡i bá» cá»™t leakage (`drop_leakage_columns()`)
  - [x] HÃ m encoding categorical variables (`encode_categorical()`)
  - [x] HÃ m scaling numerical features (`scale_numerical()`)
  - [x] Pipeline hoÃ n chá»‰nh (`clean_data()`)
  - [x] Save/load artifacts (`save_artifacts()`, `load_artifacts()`)

### 3.2. Táº¡o module features âœ…
- [x] `src/features/__init__.py`
- [x] `src/features/builder.py`
  - [x] Rá»i ráº¡c hoÃ¡ `lead_time` (`discretize_lead_time()`)
  - [x] Rá»i ráº¡c hoÃ¡ `country` (`discretize_country()`)
  - [x] Táº¡o feature `total_guests` = adults + children + babies
  - [x] Táº¡o feature `total_nights` = stays_in_weekend_nights + stays_in_week_nights
  - [x] Táº¡o feature `is_repeated_guest_and_canceled_before` (`repeated_and_canceled_before`)
  - [x] Táº¡o feature theo mÃ¹a tá»« arrival_date_month (`create_season_features()`)
  - [x] Feature cho association rules (`prepare_for_association_rules()`)
  - [x] ThÃªm nhiá»u features khÃ¡c: revenue, booking, room, guest history

### 3.3. Notebook 02_preprocess_feature.ipynb âœ…
- [x] Táº¡o notebook `notebooks/02_preprocess_feature.ipynb`
- [x] Gá»i cleaner Ä‘á»ƒ xá»­ lÃ½ missing/outliers
- [x] Gá»i builder Ä‘á»ƒ táº¡o features
- [x] LÆ°u dá»¯ liá»‡u Ä‘Ã£ xá»­ lÃ½ vÃ o `data/processed/`
- [x] Thá»‘ng kÃª trÆ°á»›c-sau tiá»n xá»­ lÃ½
- [x] Train/Test split (80/20 hoáº·c theo params.yaml)
- [x] Xá»­ lÃ½ imbalance: SMOTE / class_weight / undersampling

---

## ğŸŸ¢ PHASE 4: KHAI PHÃ TRI THá»¨C (DATA MINING)

### 4.1. Luáº­t káº¿t há»£p (Association Rules) âœ…
- [x] `src/mining/__init__.py`
- [x] `src/mining/association.py`
  - [x] HÃ m chuyá»ƒn Ä‘á»•i data sang dáº¡ng transaction (`prepare_transactions()`)
  - [x] HÃ m cháº¡y Apriori/FP-Growth (`run_apriori()`, `run_fpgrowth()`)
  - [x] HÃ m trÃ­ch xuáº¥t rules vá»›i support/confidence/lift (`extract_rules()`)
  - [x] HÃ m lá»c rules theo consequent (`filter_rules_by_consequent()`)
  - [x] HÃ m so sÃ¡nh rules theo nhÃ³m (`compare_rules_by_group()`)
  - [x] Pipeline hoÃ n chá»‰nh (`mine_association_rules()`)
  - [x] Visualization functions (`plot_rules_heatmap()`, `plot_support_confidence_scatter()`)
### 4.2. PhÃ¢n cá»¥m (Clustering) âœ…
- [x] `src/mining/clustering.py`
  - [x] HÃ m chuáº©n hoÃ¡ features cho clustering (`prepare_clustering_data()`)
  - [x] HÃ m KMeans vá»›i Elbow method (`run_kmeans()`, `find_optimal_k()`)
  - [x] HÃ m DBSCAN (`run_dbscan()`)
  - [x] HÃ m Hierarchical Clustering (`run_hierarchical()`)
  - [x] HÃ m Ä‘Ã¡nh giÃ¡: Silhouette Score, Davies-Bouldin Index (`evaluate_clustering()`)
  - [x] HÃ m profiling cá»¥m (`profile_clusters()`, `identify_high_risk_clusters()`)
  - [x] Visualization functions (`plot_clusters_2d()`, `plot_cluster_profiles()`, `plot_cancellation_by_cluster()`)
  - [x] Pipeline hoÃ n chá»‰nh (`cluster_bookings()`)

### 4.3. Notebook 03_mining_clustering.ipynb âœ…
- [x] Táº¡o notebook `notebooks/03_mining_clustering.ipynb`
- [x] **Luáº­t káº¿t há»£p:**
  - [x] TÃ¬m rules liÃªn quan Ä‘áº¿n `is_canceled=1`
  - [x] So sÃ¡nh rules theo mÃ¹a (summer vs winter)
  - [x] So sÃ¡nh rules theo quá»‘c gia (top countries)
  - [x] Visualize top rules (heatmap, network graph)
- [x] **PhÃ¢n cá»¥m:**
  - [x] Chá»n features phÃ¹ há»£p (lead_time, total_nights, adr, etc.)
  - [x] TÃ¬m sá»‘ cá»¥m tá»‘i Æ°u (Elbow + Silhouette)
  - [x] Cháº¡y KMeans vá»›i k tá»‘i Æ°u
  - [x] Profiling tá»«ng cá»¥m
  - [x] XÃ¡c Ä‘á»‹nh cá»¥m cÃ³ rá»§i ro huá»· cao
  - [x] Visualize clusters (PCA/t-SNE 2D)

### Output
- `association_rules_scatter.png`, `cancellation_rules_heatmap.png`
- `clustering_optimal_k.png`, `kmeans_clusters_pca.png`
- `kmeans_cluster_profiles.png`, `hierarchical_clusters_pca.png`
- `association_rules_cancellation.csv`, `clustering_comparison.csv`

---

## ğŸ”µ PHASE 5: MÃ” HÃŒNH PHÃ‚N Lá»šP (CLASSIFICATION) âœ…

### 5.1. Táº¡o module models âœ…
- [x] `src/models/__init__.py`
- [x] `src/models/supervised.py`
  - [x] HÃ m train Logistic Regression (baseline 1)
  - [x] HÃ m train Decision Tree (baseline 2)
  - [x] HÃ m train Random Forest
  - [x] HÃ m train XGBoost/LightGBM
  - [x] HÃ m hyperparameter tuning (GridSearch/RandomSearch)
  - [x] HÃ m predict vÃ  predict_proba

### 5.2. Táº¡o module evaluation âœ…
- [x] `src/evaluation/__init__.py`
- [x] `src/evaluation/metrics.py`
  - [x] HÃ m tÃ­nh Accuracy, Precision, Recall, F1
  - [x] HÃ m tÃ­nh PR-AUC, ROC-AUC
  - [x] HÃ m váº½ Confusion Matrix
  - [x] HÃ m váº½ ROC Curve, PR Curve
  - [x] HÃ m váº½ Feature Importance

### 5.3. Notebook 04_modeling.ipynb âœ…
- [x] Táº¡o notebook `notebooks/04_modeling.ipynb`
- [x] **Baseline models:**
  - [x] Train Logistic Regression
  - [x] Train Decision Tree
- [x] **Improved models:**
  - [x] Train Random Forest vá»›i tuning
  - [x] Train XGBoost/LightGBM vá»›i tuning
- [x] **ÄÃ¡nh giÃ¡:**
  - [x] Báº£ng so sÃ¡nh metrics (Accuracy, F1, PR-AUC, ROC-AUC)
  - [x] Confusion matrix cho má»—i model
  - [x] Feature importance analysis
  - [x] Cross-validation (5-fold)
- [x] **Kiá»ƒm tra leakage:**
  - [x] Verify khÃ´ng dÃ¹ng cá»™t reservation_status
  - [x] Verify split Ä‘Ãºng (khÃ´ng data leak tá»« test)

---

## ğŸŸ£ PHASE 6: BÃN GIÃM SÃT (SEMI-SUPERVISED) âœ…

### 6.1. Táº¡o module semi-supervised âœ…
- [x] `src/models/semi_supervised.py`
  - [x] HÃ m táº¡o labeled/unlabeled split (5%, 10%, 20% labeled)
  - [x] HÃ m Self-Training vá»›i threshold cao (0.9, 0.95)
  - [x] HÃ m Label Propagation
  - [x] HÃ m Label Spreading
  - [x] HÃ m phÃ¢n tÃ­ch pseudo-label errors

### 6.2. Notebook 04b_semi_supervised.ipynb âœ…
- [x] Táº¡o notebook `notebooks/04b_semi_supervised.ipynb`
- [x] **Ká»‹ch báº£n thiáº¿u nhÃ£n:**
  - [x] Giá»¯ 5% labeled â†’ train supervised vs semi-supervised
  - [x] Giá»¯ 10% labeled â†’ train supervised vs semi-supervised
  - [x] Giá»¯ 20% labeled â†’ train supervised vs semi-supervised
- [x] **So sÃ¡nh:**
  - [x] Supervised-only vá»›i Ã­t nhÃ£n
  - [x] Self-training (ngÆ°á»¡ng confidence 0.9, 0.95)
  - [x] Label Spreading
- [x] **PhÃ¢n tÃ­ch:**
  - [x] Learning curve theo % nhÃ£n
  - [x] PhÃ¢n tÃ­ch pseudo-label sai theo lead_time dÃ i
  - [x] Confusion matrix cá»§a pseudo-labels
  - [x] Báº£ng so sÃ¡nh F1/PR-AUC

---

## âœ… PHASE 7: CHUá»–I THá»œI GIAN (TIME SERIES)

### 7.1. Táº¡o module forecasting
- [x] `src/models/forecasting.py`
  - [x] HÃ m aggregate cancellation rate theo thÃ¡ng (`prepare_time_series`)
  - [x] HÃ m train ARIMA/SARIMA (`train_arima`, `train_sarima`)
  - [x] HÃ m train Exponential Smoothing (`train_exponential_smoothing`)
  - [x] HÃ m train Prophet (optional) (`train_prophet`)
  - [x] HÃ m Ä‘Ã¡nh giÃ¡ MAE, RMSE, MAPE (`evaluate_forecast`)
  - [x] HÃ m baseline forecasts (`naive_forecast`, `moving_average_forecast`)
  - [x] HÃ m phÃ¢n tÃ­ch time series (`check_stationarity`, `decompose_time_series`)
  - [x] HÃ m visualization (`plot_time_series`, `plot_forecast`, `plot_decomposition`)

### 7.2. Notebook Time Series Analysis
- [x] Táº¡o `notebooks/05_time_series.ipynb`
- [x] Aggregate data theo thÃ¡ng: cancellation_rate = canceled/total
- [x] Visualize time series cá»§a cancellation rate
- [x] PhÃ¢n tÃ­ch stationarity (ADF test) - Series is NON-STATIONARY
- [x] Decomposition: Trend, Seasonal, Residual components
- [x] ACF/PACF analysis
- [x] Train-Test split (20 train, 6 test months)
- [x] Train models:
  - [x] Baseline: Naive, MA(3), MA(6)
  - [x] ARIMA(1,1,1), ARIMA(2,1,2)
  - [x] Exponential Smoothing
- [x] ÄÃ¡nh giÃ¡ MAE/RMSE/MAPE
- [x] Visualize forecast vs actual
- [x] So sÃ¡nh táº¥t cáº£ models
### 7.3. Output files
- [x] `outputs/figures/ts_cancellation_rate.png`
- [x] `outputs/figures/ts_bookings_cancellations.png`
- [x] `outputs/figures/ts_decomposition.png`
- [x] `outputs/figures/ts_acf_pacf.png`
- [x] `outputs/figures/ts_train_test_split.png`
- [x] `outputs/figures/ts_model_comparison.png`
- [x] `outputs/figures/ts_best_forecast.png`
- [x] `outputs/figures/ts_all_forecasts.png`
- [x] `outputs/tables/ts_model_comparison.csv`
- [x] `outputs/tables/ts_summary_report.txt`

---

## âœ… PHASE 8: Tá»”NG Há»¢P & BÃO CÃO - HOÃ€N THÃ€NH!

### 8.1. Táº¡o module visualization âœ…
- [x] `src/visualization/__init__.py`
- [x] `src/visualization/plots.py`
  - [x] HÃ m váº½ distribution plot
  - [x] HÃ m váº½ correlation heatmap
  - [x] HÃ m váº½ model comparison bar chart
  - [x] HÃ m váº½ radar chart
  - [x] HÃ m váº½ confusion matrix detailed
  - [x] HÃ m váº½ feature importance bar
  - [x] HÃ m váº½ cumulative importance
  - [x] HÃ m váº½ learning curve

### 8.2. Táº¡o module report âœ…
- [x] `src/evaluation/report.py`
  - [x] HÃ m táº¡o báº£ng tá»•ng há»£p káº¿t quáº£
  - [x] HÃ m export figures
  - [x] HÃ m export tables (CSV/JSON)
  - [x] HÃ m generate_summary_report
  - [x] HÃ m generate_full_report
  - [x] HÃ m extract_business_insights
### 8.3. Notebook 06_evaluation_report.ipynb âœ…
- [x] Táº¡o notebook `notebooks/06_evaluation_report.ipynb`
- [x] **Tá»•ng há»£p káº¿t quáº£:**
  - [x] Báº£ng so sÃ¡nh táº¥t cáº£ models (supervised, semi-supervised, time series)
  - [x] Model comparison bar chart & radar chart
  - [x] Best model selection vá»›i justification
- [x] **PhÃ¢n tÃ­ch lá»—i:**
  - [x] Error analysis cá»§a best model
  - [x] Confusion matrix detailed
  - [x] Classification report
- [x] **Insights (9 actionable insights):**
  - [x] Insight 1: Äáº·c Ä‘iá»ƒm booking dá»… huá»· (Top 5 Features)
  - [x] Insight 2: Thá»i Ä‘iá»ƒm rá»§i ro cao (Lead Time Analysis)
  - [x] Insight 3: PhÃ¢n khÃºc khÃ¡ch hÃ ng rá»§i ro
  - [x] Insight 4: Deposit Type Analysis
  - [x] Insight 5: Market Segment Analysis
  - [x] Insight 6: Customer Type Analysis
  - [x] Insight 7: Model Performance Insights
  - [x] Insight 8: Booking Trend Analysis
  - [x] Insight 9: Special Requests Impact
- [x] **Export outputs:**
  - [x] LÆ°u figures vÃ o `outputs/figures/`
  - [x] LÆ°u tables vÃ o `outputs/tables/`
  - [x] LÆ°u reports vÃ o `outputs/reports/`
### 8.4. Output Files âœ…
- [x] `outputs/figures/supervised_comparison_bar.png`
- [x] `outputs/figures/supervised_comparison_radar.png`
- [x] `outputs/figures/model_ranking_f1.png`
- [x] `outputs/figures/confusion_matrix_best_model.png`
- [x] `outputs/figures/error_distribution.png`
- [x] `outputs/figures/feature_importance_top15.png`
- [x] `outputs/figures/cumulative_importance.png`
- [x] `outputs/figures/lead_time_analysis.png`
- [x] `outputs/figures/monthly_trend.png`
- [x] `outputs/figures/cancellation_by_deposit.png`
- [x] `outputs/figures/cancellation_by_segment.png`
- [x] `outputs/figures/cancellation_by_customer.png`
- [x] `outputs/figures/summary_dashboard.png`
- [x] `outputs/tables/project_summary.csv`
- [x] `outputs/reports/business_insights.json`
- [x] `outputs/reports/business_insights.md`
- [x] `outputs/reports/summary_report.md`
- [x] `outputs/reports/full_report.md`
- [x] `outputs/reports/supervised_results.csv`
- [x] `outputs/reports/semi_supervised_results.csv`
- [x] `outputs/reports/time_series_results.csv`
- [x] `outputs/reports/feature_importance.csv`
---

## âœ… PHASE 9: PIPELINE & REPRODUCIBILITY

### 9.1. Táº¡o scripts âœ…
- [x] `scripts/__init__.py` - Module init
- [x] `scripts/run_pipeline.py` - Cháº¡y toÃ n bá»™ pipeline
  - [x] Support CLI arguments: --all, --eda, --preprocess, --mining, --modeling, --semi, --timeseries, --report
  - [x] Support --seed argument Ä‘á»ƒ override random seed
  - [x] Logging Ä‘áº§y Ä‘á»§ vÃ o outputs/logs/
  - [x] Summary report sau khi cháº¡y
- [x] `scripts/run_papermill.py` - Cháº¡y notebooks báº±ng papermill
  - [x] List notebooks available
  - [x] Run specific notebook
  - [x] Run all notebooks in order
  - [x] Verify reproducibility
- [x] `scripts/verify_reproducibility.py` - Kiá»ƒm tra reproducibility
  - [x] Verify random operations
  - [x] Verify model training
  - [x] Run mini pipeline vÃ  so sÃ¡nh results
  - [x] Check output file hashes

### 9.2. Kiá»ƒm tra reproducibility âœ…
- [x] Cháº¡y láº¡i tá»« Ä‘áº§u vá»›i seed cá»‘ Ä‘á»‹nh (seed=42)
- [x] Verify outputs giá»‘ng nhau (F1: 0.803497, Accuracy: 0.864436)
- [x] Random operations consistent (numpy, sklearn, pandas)
- [x] Model training consistent
### 9.3. Usage Examples
```bash
# Run complete pipeline
python scripts/run_pipeline.py --all --seed 42

# Run specific phase
python scripts/run_pipeline.py --modeling
python scripts/run_pipeline.py --timeseries

# Verify reproducibility
python scripts/verify_reproducibility.py --full

# Run notebooks with papermill
python scripts/run_papermill.py --list
python scripts/run_papermill.py --notebook 01
```

---

## âœ… PHASE 10: DEMO APP

### 10.1. Demo App âœ…
- [x] Táº¡o `app/` folder vá»›i cáº¥u trÃºc module
- [x] `app/__init__.py` - Module init
- [x] `app/streamlit_app.py` - Streamlit demo app
  - [x] Input form: ThÃ´ng tin khÃ¡ch sáº¡n, khÃ¡ch hÃ ng, Ä‘áº·t phÃ²ng
  - [x] Load model Random Forest (Tuned)
  - [x] Dá»± Ä‘oÃ¡n xÃ¡c suáº¥t huá»· vá»›i color-coded risk level
  - [x] Hiá»ƒn thá»‹ cÃ¡c yáº¿u tá»‘ áº£nh hÆ°á»Ÿng chÃ­nh
  - [x] Khuyáº¿n nghá»‹ hÃ nh Ä‘á»™ng cho khÃ¡ch sáº¡n
- [x] `app/README.md` - HÆ°á»›ng dáº«n sá»­ dá»¥ng app

### 10.2. App Features
- **Input Form**: 3 cá»™t vá»›i cÃ¡c trÆ°á»ng thÃ´ng tin booking
  - ThÃ´ng tin khÃ¡ch sáº¡n: Hotel type, thÃ¡ng Ä‘áº¿n, lead time, sá»‘ Ä‘Ãªm
  - ThÃ´ng tin khÃ¡ch: Sá»‘ ngÆ°á»i, khÃ¡ch quen, loáº¡i khÃ¡ch hÃ ng, quá»‘c gia
  - ThÃ´ng tin Ä‘áº·t phÃ²ng: PhÃ¢n khÃºc, Ä‘áº·t cá»c, meal, phÃ²ng, giÃ¡, yÃªu cáº§u Ä‘áº·c biá»‡t
- **Output**:
  - XÃ¡c suáº¥t huá»· (%) vá»›i mÃ u theo má»©c rá»§i ro
  - Risk Level: LOW/MEDIUM/HIGH vá»›i icons
  - Key Factors: PhÃ¢n tÃ­ch cÃ¡c yáº¿u tá»‘ áº£nh hÆ°á»Ÿng
  - Recommendations: Khuyáº¿n nghá»‹ cho khÃ¡ch sáº¡n
  - Booking Summary: TÃ³m táº¯t thÃ´ng tin Ä‘áº·t phÃ²ng
### 10.3. Run App
```bash
# Run Streamlit app
streamlit run app/streamlit_app.py
```

### 10.4. Output Files
- [x] `app/__init__.py`
- [x] `app/streamlit_app.py`
---

## âœ… PHASE 11: BÃO CÃO CUá»I CÃ™NG - HOÃ€N THÃ€NH!

### 11.1. Viáº¿t bÃ¡o cÃ¡o
- [ ] **Pháº§n 1:** Äáº·t váº¥n Ä‘á» vÃ  phÃ¢n tÃ­ch yÃªu cáº§u
- [ ] **Pháº§n 2:** Thiáº¿t káº¿ giáº£i phÃ¡p vÃ  quy trÃ¬nh khai phÃ¡
- [ ] **Pháº§n 3:** PhÃ¢n tÃ­ch mÃ£ nguá»“n vÃ  chá»©c nÄƒng
- [ ] **Pháº§n 4:** Thá»­ nghiá»‡m vÃ  káº¿t quáº£
- [ ] **Pháº§n 5:** Tháº£o luáº­n vÃ  so sÃ¡nh
- [ ] **Pháº§n 6:** Tá»•ng káº¿t vÃ  hÆ°á»›ng phÃ¡t triá»ƒn

### 11.2. HoÃ n thiá»‡n âœ…
- [x] Review toÃ n bá»™ code
- [x] Clean up notebooks
- [x] Update README.md
  - [x] Cáº­p nháº­t cáº¥u trÃºc thÆ° má»¥c Ä‘áº§y Ä‘á»§
  - [x] ThÃªm báº£ng káº¿t quáº£ model performance
  - [x] ThÃªm hÆ°á»›ng dáº«n sá»­ dá»¥ng chi tiáº¿t
  - [x] ThÃªm hÆ°á»›ng dáº«n demo app
  - [x] ThÃªm business insights
  - [x] ThÃªm tech stack
  - [x] Format chuyÃªn nghiá»‡p vá»›i badges
- [x] Final commit vÃ  push to GitHub (ready)
- [x] Export bÃ¡o cÃ¡o vÃ o `outputs/reports/`
  - [x] `outputs/reports/final_report.md` - BÃ¡o cÃ¡o cuá»‘i cÃ¹ng

## ğŸš€ PHASE 12: PHÃT TRIá»‚N Má» Rá»˜NG

> **Ghi chÃº:** CÃ¡c tÃ­nh nÄƒng dÆ°á»›i Ä‘Ã¢y Ä‘á»™c láº­p vá»›i nhau, cÃ³ thá»ƒ thá»±c hiá»‡n theo thá»© tá»± báº¥t ká»³.  
> **Táº­p trung:** CÃ¡c ká»¹ thuáº­t Data Mining nÃ¢ng cao vÃ  á»©ng dá»¥ng thá»±c táº¿.

---

### 12.1. ğŸ” Giáº£i thÃ­ch mÃ´ hÃ¬nh (SHAP/LIME)
**Má»¥c tiÃªu:** Giáº£i thÃ­ch chi tiáº¿t táº¡i sao mÃ´ hÃ¬nh Ä‘Æ°a ra dá»± Ä‘oÃ¡n - Interpretable ML

- [ ] CÃ i Ä‘áº·t `shap`, `lime`
- [ ] Táº¡o `src/evaluation/explainability.py`
  - [ ] `compute_shap_values()` - TÃ­nh SHAP values toÃ n cá»¥c & cá»¥c bá»™
  - [ ] `plot_shap_summary()` - Biá»ƒu Ä‘á»“ tá»•ng há»£p SHAP
  - [ ] `plot_shap_waterfall()` - Biá»ƒu Ä‘á»“ thÃ¡c nÆ°á»›c cho tá»«ng dá»± Ä‘oÃ¡n
  - [ ] `plot_shap_dependence()` - Biá»ƒu Ä‘á»“ phá»¥ thuá»™c feature
  - [ ] `lime_explain_instance()` - LIME cho dá»± Ä‘oÃ¡n Ä‘Æ¡n láº»
- [ ] Táº¡o notebook `07_explainability.ipynb`
  - [ ] Táº§m quan trá»ng Ä‘áº·c trÆ°ng toÃ n cá»¥c vá»›i SHAP
  - [ ] Giáº£i thÃ­ch cá»¥c bá»™ cho cÃ¡c trÆ°á»ng há»£p thÃº vá»‹ (FP, FN)
  - [ ] So sÃ¡nh SHAP vs Feature Importance truyá»n thá»‘ng
  - [ ] PhÃ¢n tÃ­ch tÆ°Æ¡ng tÃ¡c giá»¯a cÃ¡c Ä‘áº·c trÆ°ng
- [ ] TÃ­ch há»£p SHAP vÃ o Streamlit app (giáº£i thÃ­ch dá»± Ä‘oÃ¡n)

**Äáº§u ra:** `shap_summary.png`, `shap_dependence_*.png`, `shap_interaction.png`

---

### 12.2. ğŸ§  MÃ´ hÃ¬nh Deep Learning (Máº¡ng nÆ¡-ron)
**Má»¥c tiÃªu:** Thá»­ nghiá»‡m Neural Network Ä‘á»ƒ so sÃ¡nh vá»›i ML truyá»n thá»‘ng

- [ ] CÃ i Ä‘áº·t `tensorflow` hoáº·c `pytorch`
- [ ] Táº¡o `src/models/deep_learning.py`:
  - [ ] `build_mlp_model()` - Máº¡ng Perceptron Ä‘a táº§ng
  - [ ] `build_embedding_model()` - MÃ´ hÃ¬nh vá»›i categorical embeddings
  - [ ] `train_nn_model()` - VÃ²ng láº·p huáº¥n luyá»‡n
  - [ ] `evaluate_nn_model()` - ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh
- [ ] Táº¡o notebook `08_deep_learning.ipynb`:
  - [ ] Tiá»n xá»­ lÃ½ dá»¯ liá»‡u cho Neural Network
  - [ ] Thiáº¿t káº¿ kiáº¿n trÃºc mÃ´ hÃ¬nh
  - [ ] Huáº¥n luyá»‡n vá»›i early stopping
  - [ ] So sÃ¡nh vá»›i Random Forest (accuracy, F1, thá»i gian)
  - [ ] PhÃ¢n tÃ­ch overfitting/underfitting
- [ ] Hyperparameter tuning vá»›i Keras Tuner

**Äáº§u ra:** `neural_network.h5`, `nn_training_history.png`, `nn_comparison.csv`

---

### 12.3. âš¡ Tá»‘i Æ°u siÃªu tham sá»‘ (Optuna)
**Má»¥c tiÃªu:** TÃ¬m hyperparameters tá»‘i Æ°u má»™t cÃ¡ch tá»± Ä‘á»™ng vá»›i Bayesian Optimization

- [ ] CÃ i Ä‘áº·t `optuna`
- [ ] Táº¡o `src/optimization/optuna_tuner.py`:
  - [ ] `create_objective()` - HÃ m má»¥c tiÃªu
  - [ ] `run_optimization()` - Cháº¡y study vá»›i nhiá»u trials
  - [ ] `visualize_optimization()` - Biá»ƒu Ä‘á»“ káº¿t quáº£
  - [ ] `get_best_params()` - Láº¥y tham sá»‘ tá»‘t nháº¥t
- [ ] Táº¡o notebook `09_hyperparameter_optimization.ipynb`:
  - [ ] Äá»‹nh nghÄ©a khÃ´ng gian tÃ¬m kiáº¿m (search space)
  - [ ] Cháº¡y 100+ trials cho Random Forest, XGBoost
  - [ ] Visualization: importance, history, contour, parallel coordinate
  - [ ] So sÃ¡nh vá»›i GridSearchCV (hiá»‡u quáº£, thá»i gian)
  - [ ] PhÃ¢n tÃ­ch convergence
- [ ] Pruning Ä‘á»ƒ tiáº¿t kiá»‡m thá»i gian tÃ­nh toÃ¡n

**Äáº§u ra:** `optuna_study.db`, `optuna_importance.png`, `optuna_history.png`

---

### 12.4. ğŸ”” PhÃ¡t hiá»‡n Data Drift & GiÃ¡m sÃ¡t mÃ´ hÃ¬nh
**Má»¥c tiÃªu:** PhÃ¡t hiá»‡n khi dá»¯ liá»‡u thay Ä‘á»•i vÃ  mÃ´ hÃ¬nh cáº§n huáº¥n luyá»‡n láº¡i

- [ ] CÃ i Ä‘áº·t `evidently`, `alibi-detect`
- [ ] Táº¡o `src/monitoring/drift_detection.py`:
  - [ ] `detect_data_drift()` - Kiá»ƒm Ä‘á»‹nh thá»‘ng kÃª (KS, Chi-square)
  - [ ] `detect_concept_drift()` - GiÃ¡m sÃ¡t hiá»‡u suáº¥t theo thá»i gian
  - [ ] `detect_feature_drift()` - Drift tá»«ng Ä‘áº·c trÆ°ng
  - [ ] `generate_drift_report()` - BÃ¡o cÃ¡o HTML
- [ ] Táº¡o notebook `10_drift_monitoring.ipynb`:
  - [ ] MÃ´ phá»ng data drift (thay Ä‘á»•i phÃ¢n phá»‘i)
  - [ ] GiÃ¡m sÃ¡t cÃ¡c Ä‘áº·c trÆ°ng quan trá»ng
  - [ ] Thiáº¿t láº­p ngÆ°á»¡ng cáº£nh bÃ¡o
  - [ ] PhÃ¢n tÃ­ch áº£nh hÆ°á»Ÿng drift Ä‘áº¿n hiá»‡u suáº¥t mÃ´ hÃ¬nh
- [ ] LÃªn lá»‹ch kiá»ƒm tra Ä‘á»‹nh ká»³

**Äáº§u ra:** `drift_report.html`, `feature_drift.png`, `performance_over_time.png`

---

### 12.5. ğŸ¯ Ká»¹ thuáº­t xá»­ lÃ½ máº¥t cÃ¢n báº±ng nÃ¢ng cao
**Má»¥c tiÃªu:** Thá»­ nghiá»‡m cÃ¡c ká»¹ thuáº­t sampling Ä‘á»ƒ xá»­ lÃ½ imbalanced data

- [ ] CÃ i Ä‘áº·t `imbalanced-learn`
- [ ] Táº¡o `src/data/sampling.py`:
  - [ ] `apply_smote()` - SMOTE oversampling
  - [ ] `apply_adasyn()` - ADASYN adaptive sampling
  - [ ] `apply_smoteenn()` - Káº¿t há»£p SMOTE + ENN
  - [ ] `apply_undersampling()` - Random undersampling
  - [ ] `compare_sampling_methods()` - So sÃ¡nh cÃ¡c phÆ°Æ¡ng phÃ¡p
- [ ] Táº¡o notebook `11_imbalanced_learning.ipynb`:
  - [ ] So sÃ¡nh: No sampling vs SMOTE vs ADASYN vs SMOTEENN
  - [ ] áº¢nh hÆ°á»Ÿng Ä‘áº¿n Precision, Recall, F1
  - [ ] Visualization: phÃ¢n phá»‘i trÆ°á»›c-sau sampling
  - [ ] TÃ¬m tá»· lá»‡ sampling tá»‘i Æ°u

**Äáº§u ra:** `sampling_comparison.png`, `sampling_results.csv`

---

### 12.6. ğŸ”— Stacking & Voting Ensemble
**Má»¥c tiÃªu:** Káº¿t há»£p nhiá»u mÃ´ hÃ¬nh Ä‘á»ƒ cáº£i thiá»‡n hiá»‡u suáº¥t

- [ ] Táº¡o `src/models/ensemble.py`:
  - [ ] `build_voting_classifier()` - Hard/Soft voting
  - [ ] `build_stacking_classifier()` - Stacking vá»›i meta-learner
  - [ ] `build_blending_classifier()` - Blending ensemble
  - [ ] `evaluate_ensemble()` - ÄÃ¡nh giÃ¡ ensemble
- [ ] Táº¡o notebook `12_ensemble_methods.ipynb`:
  - [ ] Voting Ensemble: RF + XGBoost + LightGBM
  - [ ] Stacking vá»›i Logistic Regression lÃ m meta-learner
  - [ ] So sÃ¡nh vá»›i single best model
  - [ ] PhÃ¢n tÃ­ch diversity cá»§a base models
  - [ ] Cross-validation cho ensemble

**Äáº§u ra:** `ensemble_comparison.png`, `stacking_model.joblib`

---

### 12.7. ğŸ“Š PhÃ¢n tÃ­ch cá»¥m nÃ¢ng cao
**Má»¥c tiÃªu:** Ãp dá»¥ng thÃªm cÃ¡c thuáº­t toÃ¡n clustering vÃ  Ä‘Ã¡nh giÃ¡

- [ ] Táº¡o `src/mining/advanced_clustering.py`:
  - [ ] `apply_gaussian_mixture()` - GMM clustering
  - [ ] `apply_spectral_clustering()` - Spectral Clustering
  - [ ] `apply_optics()` - OPTICS (density-based)
  - [ ] `find_optimal_clusters()` - Elbow, Silhouette, Gap statistic
  - [ ] `cluster_stability_analysis()` - PhÃ¢n tÃ­ch á»•n Ä‘á»‹nh cá»¥m
- [ ] Táº¡o notebook `13_advanced_clustering.ipynb`:
  - [ ] So sÃ¡nh: KMeans vs GMM vs DBSCAN vs Spectral
  - [ ] ÄÃ¡nh giÃ¡: Silhouette, Calinski-Harabasz, Davies-Bouldin
  - [ ] PhÃ¢n tÃ­ch á»•n Ä‘á»‹nh cá»¥m vá»›i bootstrap
  - [ ] Profiling chi tiáº¿t tá»«ng cá»¥m

**Äáº§u ra:** `clustering_comparison_advanced.png`, `cluster_stability.csv`

---

### 12.8. ğŸ”€ Feature Selection nÃ¢ng cao
**Má»¥c tiÃªu:** TÃ¬m táº­p Ä‘áº·c trÆ°ng tá»‘i Æ°u vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p khÃ¡c nhau

- [ ] Táº¡o `src/features/selection.py`:
  - [ ] `recursive_feature_elimination()` - RFE
  - [ ] `boruta_selection()` - Boruta algorithm
  - [ ] `genetic_algorithm_selection()` - GA-based selection
  - [ ] `mutual_information_selection()` - MI-based
  - [ ] `compare_selection_methods()` - So sÃ¡nh
- [ ] Táº¡o notebook `14_feature_selection.ipynb`:
  - [ ] Filter methods: Chi-square, Mutual Information
  - [ ] Wrapper methods: RFE, Forward/Backward selection
  - [ ] Embedded methods: LASSO, Tree-based importance
  - [ ] So sÃ¡nh sá»‘ lÆ°á»£ng features vs hiá»‡u suáº¥t
  - [ ] Stability cá»§a feature selection

**Äáº§u ra:** `feature_selection_comparison.png`, `selected_features.csv`

---

### 12.9. ğŸ“ˆ PhÃ¢n tÃ­ch chuá»—i thá»i gian nÃ¢ng cao
**Má»¥c tiÃªu:** Ãp dá»¥ng cÃ¡c mÃ´ hÃ¬nh time series phá»©c táº¡p hÆ¡n

- [ ] CÃ i Ä‘áº·t `prophet`, `neuralprophet`
- [ ] Táº¡o `src/models/advanced_forecasting.py`:
  - [ ] `prophet_forecast()` - Facebook Prophet
  - [ ] `neural_prophet_forecast()` - NeuralProphet
  - [ ] `ensemble_forecast()` - Ensemble of forecasters
  - [ ] `detect_anomalies()` - PhÃ¡t hiá»‡n Ä‘iá»ƒm báº¥t thÆ°á»ng
- [ ] Táº¡o notebook `15_advanced_time_series.ipynb`:
  - [ ] Prophet vá»›i seasonality, holidays
  - [ ] So sÃ¡nh: ARIMA vs Prophet vs NeuralProphet
  - [ ] PhÃ¡t hiá»‡n anomaly trong cancellation rate
  - [ ] Dá»± bÃ¡o dÃ i háº¡n vá»›i confidence intervals
  - [ ] What-if analysis

**Äáº§u ra:** `prophet_forecast.png`, `anomaly_detection.png`, `forecast_comparison.csv`

---

### 12.10. ğŸ² PhÃ¢n tÃ­ch Bayesian
**Má»¥c tiÃªu:** Ãp dá»¥ng Bayesian inference cho uncertainty quantification

- [ ] CÃ i Ä‘áº·t `pymc`, `arviz`
- [ ] Táº¡o `src/models/bayesian.py`:
  - [ ] `bayesian_logistic_regression()` - Bayesian LR
  - [ ] `posterior_predictive_check()` - Kiá»ƒm tra posterior
  - [ ] `credible_intervals()` - Khoáº£ng tin cáº­y Bayesian
- [ ] Táº¡o notebook `16_bayesian_analysis.ipynb`:
  - [ ] Prior selection cho cÃ¡c tham sá»‘
  - [ ] MCMC sampling vá»›i PyMC
  - [ ] So sÃ¡nh: Frequentist vs Bayesian
  - [ ] Uncertainty quantification cho predictions
  - [ ] Visualization vá»›i ArviZ

**Äáº§u ra:** `posterior_distribution.png`, `credible_intervals.png`

---

### 12.11. ğŸŒ REST API triá»ƒn khai (FastAPI)
**Má»¥c tiÃªu:** Expose mÃ´ hÃ¬nh qua REST API Ä‘á»ƒ tÃ­ch há»£p vá»›i há»‡ thá»‘ng khÃ¡c

- [ ] CÃ i Ä‘áº·t `fastapi`, `uvicorn`, `pydantic`
- [ ] Táº¡o `api/` folder:
  ```
  api/
  â”œâ”€â”€ main.py           # FastAPI app
  â”œâ”€â”€ schemas.py        # Pydantic models
  â”œâ”€â”€ routes/
  â”‚   â”œâ”€â”€ predict.py    # /predict endpoint
  â”‚   â””â”€â”€ health.py     # /health endpoint
  â””â”€â”€ utils.py          # HÃ m há»— trá»£
  ```
- [ ] Endpoints:
  - [ ] `POST /predict` - Dá»± Ä‘oÃ¡n Ä‘Æ¡n booking
  - [ ] `POST /predict/batch` - Dá»± Ä‘oÃ¡n hÃ ng loáº¡t
  - [ ] `GET /model/info` - ThÃ´ng tin mÃ´ hÃ¬nh
  - [ ] `GET /health` - Kiá»ƒm tra tráº¡ng thÃ¡i
- [ ] API documentation vá»›i Swagger UI
- [ ] Unit tests cho API endpoints

**Cháº¡y:** `uvicorn api.main:app --reload`

---

### 12.12. ğŸ³ ÄÃ³ng gÃ³i Docker
**Má»¥c tiÃªu:** ÄÃ³ng gÃ³i á»©ng dá»¥ng Ä‘á»ƒ triá»ƒn khai dá»… dÃ ng

- [ ] Táº¡o `Dockerfile` cho Streamlit app
- [ ] Táº¡o `Dockerfile.api` cho FastAPI (náº¿u cÃ³)
- [ ] Táº¡o `docker-compose.yml`:
  - [ ] Service: streamlit-app
  - [ ] Service: fastapi (tÃ¹y chá»n)
  - [ ] Volume mount cho models
- [ ] Táº¡o `.dockerignore`
- [ ] Test build vÃ  cháº¡y locally
- [ ] TÃ i liá»‡u hÆ°á»›ng dáº«n triá»ƒn khai

**Cháº¡y:** `docker-compose up -d`

---

### 12.13. ğŸ§ª Kiá»ƒm thá»­ tá»± Ä‘á»™ng (pytest)
**Má»¥c tiÃªu:** Äáº£m báº£o cháº¥t lÆ°á»£ng code vá»›i automated tests

- [ ] CÃ i Ä‘áº·t `pytest`, `pytest-cov`
- [ ] Táº¡o `tests/` folder:
  ```
  tests/
  â”œâ”€â”€ __init__.py
  â”œâ”€â”€ conftest.py           # Fixtures
  â”œâ”€â”€ test_cleaner.py       # Test tiá»n xá»­ lÃ½
  â”œâ”€â”€ test_builder.py       # Test feature engineering
  â”œâ”€â”€ test_models.py        # Test huáº¥n luyá»‡n/dá»± Ä‘oÃ¡n
  â””â”€â”€ test_evaluation.py    # Test metrics
  ```
- [ ] Viáº¿t tests cho cÃ¡c modules (â‰¥80% coverage)
- [ ] Táº¡o `pytest.ini` configuration
- [ ] Coverage report â‰¥70%

**Cháº¡y:** `pytest tests/ -v --cov=src --cov-report=html`

---

### 12.14. ğŸ“Š Theo dÃµi thÃ­ nghiá»‡m (MLflow)
**Má»¥c tiÃªu:** Theo dÃµi experiments, parameters, metrics cÃ³ há»‡ thá»‘ng

- [ ] CÃ i Ä‘áº·t `mlflow`
- [ ] Táº¡o `src/tracking/mlflow_utils.py`:
  - [ ] `log_experiment()` - Ghi params, metrics, artifacts
  - [ ] `register_model()` - ÄÄƒng kÃ½ mÃ´ hÃ¬nh
  - [ ] `load_production_model()` - Táº£i mÃ´ hÃ¬nh tá»« registry
- [ ] TÃ­ch há»£p vÃ o training notebooks:
  - [ ] Ghi hyperparameters
  - [ ] Ghi metrics (F1, ROC-AUC, v.v.)
  - [ ] Ghi confusion matrix nhÆ° artifact
  - [ ] Ghi model artifacts
- [ ] MLflow UI Ä‘á»ƒ so sÃ¡nh experiments

**Cháº¡y:** `mlflow ui --port 5000`

---

## ğŸ“ Cáº¤U TRÃšC THÆ¯ Má»¤C HIá»†N Táº I

```
Nhom12_BaiTapLon_DataMining/
â”œâ”€â”€ README.md                    # HÆ°á»›ng dáº«n
â”œâ”€â”€ requirements.txt             # Dependencies
â”œâ”€â”€ TODO.md                      # File nÃ y
â”œâ”€â”€ blog_post.md                 # Blog káº¿t quáº£
â”œâ”€â”€ BaiTapLonToDo.txt           # YÃªu cáº§u Ä‘á» bÃ i
â”‚
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ params.yaml              # Tham sá»‘ cáº¥u hÃ¬nh
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ raw/
â”‚       â””â”€â”€ hotel_bookings.csv   # Dataset gá»‘c (119,390 rows)
â”‚
â”œâ”€â”€ notebooks/                   # 7 Jupyter Notebooks
â”‚   â”œâ”€â”€ 01_eda.ipynb
â”‚   â”œâ”€â”€ 02_preprocess_feature.ipynb
â”‚   â”œâ”€â”€ 03_mining_clustering.ipynb
â”‚   â”œâ”€â”€ 04_modeling.ipynb
â”‚   â”œâ”€â”€ 04b_semi_supervised.ipynb
â”‚   â”œâ”€â”€ 05_time_series.ipynb
â”‚   â””â”€â”€ 06_evaluation_report.ipynb
â”‚
â”œâ”€â”€ src/                         # Source code modules
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ loader.py
â”‚   â”‚   â””â”€â”€ cleaner.py
â”‚   â”œâ”€â”€ features/
â”‚   â”‚   â””â”€â”€ builder.py
â”‚   â”œâ”€â”€ mining/
â”‚   â”‚   â”œâ”€â”€ association.py
â”‚   â”‚   â””â”€â”€ clustering.py
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ supervised.py
â”‚   â”‚   â”œâ”€â”€ semi_supervised.py
â”‚   â”‚   â””â”€â”€ forecasting.py
â”‚   â”œâ”€â”€ evaluation/
â”‚   â”‚   â”œâ”€â”€ metrics.py
â”‚   â”‚   â””â”€â”€ report.py
â”‚   â””â”€â”€ visualization/
â”‚       â””â”€â”€ plots.py
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ run_pipeline.py
â”‚   â”œâ”€â”€ run_papermill.py
â”‚   â””â”€â”€ verify_reproducibility.py
â”‚
â”œâ”€â”€ app/
â”‚   â””â”€â”€ streamlit_app.py         # Demo app
â”‚
â””â”€â”€ outputs/
    â”œâ”€â”€ figures/                 # 52 biá»ƒu Ä‘á»“ PNG
    â”œâ”€â”€ tables/                  # 13 CSV files
    â”œâ”€â”€ models/                  # 7 trained models
    â””â”€â”€ reports/                 # Reports (MD, JSON, CSV)
```

---

## âš ï¸ LÆ¯U Ã QUAN TRá»ŒNG

1. **Data Leakage**: ÄÃ£ loáº¡i bá» `reservation_status`, `reservation_status_date`
2. **Imbalanced Data**: Sá»­ dá»¥ng class_weight, Ä‘Ã¡nh giÃ¡ báº±ng F1/PR-AUC
3. **Reproducibility**: Seed=42, káº¿t quáº£ consistent
4. **Code Quality**: Notebooks gá»i hÃ m tá»« src/, cÃ³ docstrings

---

## ğŸ¯ CHECKLIST TRÆ¯á»šC KHI Ná»˜P

- [x] Táº¥t cáº£ notebooks cháº¡y thÃ nh cÃ´ng vá»›i `run_papermill.py --all`
- [x] README.md Ä‘áº§y Ä‘á»§ hÆ°á»›ng dáº«n
- [x] requirements.txt cáº­p nháº­t
- [x] Outputs Ä‘áº§y Ä‘á»§ (figures, tables, models, reports)
- [x] Demo app hoáº¡t Ä‘á»™ng
- [x] Code cÃ³ comments/docstrings
- [ ] Export BaoCao.pdf
- [ ] Push to GitHub

---
