{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b56244bd",
   "metadata": {},
   "source": [
    "## 1. Setup & Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf47313b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Libraries imported successfully!\n",
      "üìÅ Project root: c:\\Coding\\DataMining\\Nhom12_BaiTapLon_DataMining\n"
     ]
    }
   ],
   "source": [
    "# Standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import warnings\n",
    "import sys\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import custom modules\n",
    "from src.data.loader import load_raw_data, get_data_info\n",
    "from src.data.cleaner import (\n",
    "    clean_data, \n",
    "    drop_leakage_columns,\n",
    "    handle_missing_values,\n",
    "    handle_outliers,\n",
    "    handle_adr_outliers,\n",
    "    get_missing_summary,\n",
    "    save_artifacts,\n",
    "    encode_categorical,\n",
    "    scale_numerical\n",
    ")\n",
    "from src.features.builder import (\n",
    "    create_all_features,\n",
    "    prepare_for_association_rules,\n",
    "    get_feature_list\n",
    ")\n",
    "\n",
    "# Settings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "# Plot settings\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")\n",
    "print(f\"üìÅ Project root: {project_root}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ac1b9b",
   "metadata": {},
   "source": [
    "## 2. Load Configuration & Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d05df9ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è Configuration loaded:\n",
      "   - Random Seed: 42\n",
      "   - Test Size: 0.2\n",
      "   - Target Column: is_canceled\n"
     ]
    }
   ],
   "source": [
    "# Load configuration\n",
    "config_path = project_root / 'configs' / 'params.yaml'\n",
    "with open(config_path, 'r', encoding='utf-8') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Extract parameters\n",
    "SEED = config['seed']\n",
    "TEST_SIZE = config['split']['test_size']\n",
    "TARGET = config['target']\n",
    "\n",
    "print(f\"‚öôÔ∏è Configuration loaded:\")\n",
    "print(f\"   - Random Seed: {SEED}\")\n",
    "print(f\"   - Test Size: {TEST_SIZE}\")\n",
    "print(f\"   - Target Column: {TARGET}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3eaaaa85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Raw Data Loaded:\n",
      "   Shape: (119390, 32)\n",
      "   Memory Usage: 104.83 MB\n"
     ]
    }
   ],
   "source": [
    "# Load raw data\n",
    "data_path = project_root / 'data' / 'raw' / 'hotel_bookings.csv'\n",
    "df_raw = pd.read_csv(data_path)\n",
    "\n",
    "print(f\"üìä Raw Data Loaded:\")\n",
    "print(f\"   Shape: {df_raw.shape}\")\n",
    "print(f\"   Memory Usage: {df_raw.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec4cbd8",
   "metadata": {},
   "source": [
    "## 3. Th·ªëng K√™ Tr∆∞·ªõc Ti·ªÅn X·ª≠ L√Ω\n",
    "\n",
    "Tr∆∞·ªõc khi x·ª≠ l√Ω, h√£y xem t√¨nh tr·∫°ng d·ªØ li·ªáu hi·ªán t·∫°i."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c207257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üìã TH·ªêNG K√ä TR∆Ø·ªöC TI·ªÄN X·ª¨ L√ù\n",
      "======================================================================\n",
      "\n",
      "üìä Shape: 119,390 rows √ó 32 columns\n",
      "\n",
      "üéØ Target Distribution (is_canceled):\n",
      "   - Not Canceled (0): 75,166 (62.96%)\n",
      "   - Canceled (1): 44,224 (37.04%)\n",
      "   ‚Üí Imbalance Ratio: 1.70:1\n",
      "\n",
      "‚ùå Missing Values Total: 129,425\n"
     ]
    }
   ],
   "source": [
    "# Overview before cleaning\n",
    "print(\"=\"*70)\n",
    "print(\"üìã TH·ªêNG K√ä TR∆Ø·ªöC TI·ªÄN X·ª¨ L√ù\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nüìä Shape: {df_raw.shape[0]:,} rows √ó {df_raw.shape[1]} columns\")\n",
    "\n",
    "# Target distribution\n",
    "target_dist = df_raw[TARGET].value_counts()\n",
    "target_pct = df_raw[TARGET].value_counts(normalize=True) * 100\n",
    "print(f\"\\nüéØ Target Distribution ({TARGET}):\")\n",
    "print(f\"   - Not Canceled (0): {target_dist[0]:,} ({target_pct[0]:.2f}%)\")\n",
    "print(f\"   - Canceled (1): {target_dist[1]:,} ({target_pct[1]:.2f}%)\")\n",
    "print(f\"   ‚Üí Imbalance Ratio: {target_dist[0]/target_dist[1]:.2f}:1\")\n",
    "\n",
    "# Missing values\n",
    "missing_total = df_raw.isnull().sum().sum()\n",
    "print(f\"\\n‚ùå Missing Values Total: {missing_total:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c350f154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìã Chi ti·∫øt Missing Values:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_7d3a9\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_7d3a9_level0_col0\" class=\"col_heading level0 col0\" >Column</th>\n",
       "      <th id=\"T_7d3a9_level0_col1\" class=\"col_heading level0 col1\" >Missing_Count</th>\n",
       "      <th id=\"T_7d3a9_level0_col2\" class=\"col_heading level0 col2\" >Missing_Pct</th>\n",
       "      <th id=\"T_7d3a9_level0_col3\" class=\"col_heading level0 col3\" >Dtype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_7d3a9_level0_row0\" class=\"row_heading level0 row0\" >24</th>\n",
       "      <td id=\"T_7d3a9_row0_col0\" class=\"data row0 col0\" >company</td>\n",
       "      <td id=\"T_7d3a9_row0_col1\" class=\"data row0 col1\" >112593</td>\n",
       "      <td id=\"T_7d3a9_row0_col2\" class=\"data row0 col2\" >94.31%</td>\n",
       "      <td id=\"T_7d3a9_row0_col3\" class=\"data row0 col3\" >float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7d3a9_level0_row1\" class=\"row_heading level0 row1\" >23</th>\n",
       "      <td id=\"T_7d3a9_row1_col0\" class=\"data row1 col0\" >agent</td>\n",
       "      <td id=\"T_7d3a9_row1_col1\" class=\"data row1 col1\" >16340</td>\n",
       "      <td id=\"T_7d3a9_row1_col2\" class=\"data row1 col2\" >13.69%</td>\n",
       "      <td id=\"T_7d3a9_row1_col3\" class=\"data row1 col3\" >float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7d3a9_level0_row2\" class=\"row_heading level0 row2\" >13</th>\n",
       "      <td id=\"T_7d3a9_row2_col0\" class=\"data row2 col0\" >country</td>\n",
       "      <td id=\"T_7d3a9_row2_col1\" class=\"data row2 col1\" >488</td>\n",
       "      <td id=\"T_7d3a9_row2_col2\" class=\"data row2 col2\" >0.41%</td>\n",
       "      <td id=\"T_7d3a9_row2_col3\" class=\"data row2 col3\" >object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7d3a9_level0_row3\" class=\"row_heading level0 row3\" >10</th>\n",
       "      <td id=\"T_7d3a9_row3_col0\" class=\"data row3 col0\" >children</td>\n",
       "      <td id=\"T_7d3a9_row3_col1\" class=\"data row3 col1\" >4</td>\n",
       "      <td id=\"T_7d3a9_row3_col2\" class=\"data row3 col2\" >0.00%</td>\n",
       "      <td id=\"T_7d3a9_row3_col3\" class=\"data row3 col3\" >float64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x24733528fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Detailed missing values\n",
    "missing_summary = get_missing_summary(df_raw)\n",
    "if len(missing_summary) > 0:\n",
    "    print(\"\\nüìã Chi ti·∫øt Missing Values:\")\n",
    "    display(missing_summary.style.format({'Missing_Pct': '{:.2f}%'}))\n",
    "else:\n",
    "    print(\"\\n‚úÖ Kh√¥ng c√≥ missing values!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4026ad8",
   "metadata": {},
   "source": [
    "## 4. Ti·ªÅn X·ª≠ L√Ω D·ªØ Li·ªáu\n",
    "\n",
    "### 4.1. Lo·∫°i b·ªè Data Leakage Columns\n",
    "\n",
    "‚ö†Ô∏è **QUAN TR·ªåNG:** C√°c c·ªôt `reservation_status` v√† `reservation_status_date` ch·ª©a th√¥ng tin v·ªÅ k·∫øt qu·∫£ ƒë·∫∑t ph√≤ng (Check-Out/Canceled/No-Show) - ƒë√¢y l√† th√¥ng tin **sau khi** booking ƒë√£ k·∫øt th√∫c, g√¢y ra **data leakage**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d52f577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîí B∆Ø·ªöC 1: Lo·∫°i b·ªè Data Leakage Columns\n",
      "--------------------------------------------------\n",
      "\n",
      "‚ö†Ô∏è C√°c c·ªôt g√¢y Data Leakage:\n",
      "   - reservation_status: 3 unique values\n",
      "     Values: {'Check-Out': 75166, 'Canceled': 43017, 'No-Show': 1207}\n",
      "   - reservation_status_date: 926 unique values\n",
      "‚úì Dropped 2 leakage column(s): ['reservation_status', 'reservation_status_date']\n",
      "\n",
      "‚úÖ Shape sau khi drop: (119390, 30)\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Drop leakage columns\n",
    "print(\"üîí B∆Ø·ªöC 1: Lo·∫°i b·ªè Data Leakage Columns\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "# Check leakage columns before dropping\n",
    "leakage_cols = ['reservation_status', 'reservation_status_date']\n",
    "print(\"\\n‚ö†Ô∏è C√°c c·ªôt g√¢y Data Leakage:\")\n",
    "for col in leakage_cols:\n",
    "    if col in df_raw.columns:\n",
    "        print(f\"   - {col}: {df_raw[col].nunique()} unique values\")\n",
    "        if col == 'reservation_status':\n",
    "            print(f\"     Values: {df_raw[col].value_counts().to_dict()}\")\n",
    "\n",
    "# Drop leakage columns\n",
    "df_step1 = drop_leakage_columns(df_raw, leakage_cols, verbose=True)\n",
    "print(f\"\\n‚úÖ Shape sau khi drop: {df_step1.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4351d0",
   "metadata": {},
   "source": [
    "### 4.2. X·ª≠ L√Ω Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bdc36040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß B∆Ø·ªöC 2: X·ª≠ l√Ω Missing Values\n",
      "--------------------------------------------------\n",
      "============================================================\n",
      "HANDLING MISSING VALUES\n",
      "============================================================\n",
      "Initial missing values: 129,425\n",
      "  ‚Üí Dropped 'company' column (94% missing)\n",
      "  ‚Üí Filled 'agent' with 0 (no agent)\n",
      "  ‚Üí Filled 'country' with mode: 'PRT'\n",
      "  ‚Üí Filled 'children' with 0\n",
      "------------------------------------------------------------\n",
      "Final missing values: 0\n",
      "Rows: 119390 ‚Üí 119390\n",
      "============================================================\n",
      "\n",
      "‚úÖ Missing values c√≤n l·∫°i: 0\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Handle missing values\n",
    "print(\"üîß B∆Ø·ªöC 2: X·ª≠ l√Ω Missing Values\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "# Use automatic strategy (defined in cleaner.py)\n",
    "df_step2 = handle_missing_values(df_step1, strategy='auto', verbose=True)\n",
    "\n",
    "# Verify no missing values remain\n",
    "remaining_missing = df_step2.isnull().sum().sum()\n",
    "print(f\"\\n‚úÖ Missing values c√≤n l·∫°i: {remaining_missing}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e1860c",
   "metadata": {},
   "source": [
    "### 4.3. X·ª≠ L√Ω Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c750205a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìà B∆Ø·ªöC 3: X·ª≠ l√Ω Outliers\n",
      "--------------------------------------------------\n",
      "\n",
      "üè∑Ô∏è ADR Statistics Before:\n",
      "   Min: -6.38\n",
      "   Max: 5400.00\n",
      "   Mean: 101.83\n",
      "   Negative values: 1\n",
      "ADR Outliers: 1 negative, 1 extreme (>5000)\n",
      "  ‚Üí Replaced 1 negative ADR with median: 94.59\n",
      "  ‚Üí Capped 1 extreme ADR at 5000\n",
      "============================================================\n",
      "HANDLING OUTLIERS\n",
      "Method: IQR, Strategy: CAP\n",
      "============================================================\n",
      "  ‚Üí lead_time: Capped 3005 outliers [-195.00, 373.00]\n",
      "  ‚Üí adr: Capped 3793 outliers [-15.77, 211.06]\n",
      "  ‚Üí stays_in_weekend_nights: Capped 265 outliers [-3.00, 5.00]\n",
      "  ‚Üí stays_in_week_nights: Capped 3354 outliers [-2.00, 6.00]\n",
      "  ‚Üí adults: Capped 29710 outliers [2.00, 2.00]\n",
      "  ‚Üí children: Capped 8590 outliers [0.00, 0.00]\n",
      "  ‚Üí babies: Capped 917 outliers [0.00, 0.00]\n",
      "  ‚Üí days_in_waiting_list: Capped 3698 outliers [0.00, 0.00]\n",
      "------------------------------------------------------------\n",
      "Total outliers handled: 53,332\n",
      "Rows: 119390 ‚Üí 119390\n",
      "============================================================\n",
      "\n",
      "‚úÖ Shape sau khi x·ª≠ l√Ω outliers: (119390, 29)\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Handle outliers\n",
    "print(\"üìà B∆Ø·ªöC 3: X·ª≠ l√Ω Outliers\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "# Special handling for ADR (Average Daily Rate)\n",
    "print(\"\\nüè∑Ô∏è ADR Statistics Before:\")\n",
    "print(f\"   Min: {df_step2['adr'].min():.2f}\")\n",
    "print(f\"   Max: {df_step2['adr'].max():.2f}\")\n",
    "print(f\"   Mean: {df_step2['adr'].mean():.2f}\")\n",
    "print(f\"   Negative values: {(df_step2['adr'] < 0).sum()}\")\n",
    "\n",
    "# Handle ADR outliers\n",
    "df_step3a = handle_adr_outliers(df_step2, min_adr=0, max_adr=5000, verbose=True)\n",
    "\n",
    "# Handle other outliers using IQR method with capping\n",
    "df_step3 = handle_outliers(\n",
    "    df_step3a,\n",
    "    method='iqr',\n",
    "    threshold=1.5,\n",
    "    strategy='cap',\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Shape sau khi x·ª≠ l√Ω outliers: {df_step3.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1930693e",
   "metadata": {},
   "source": [
    "## 5. Feature Engineering\n",
    "\n",
    "T·∫°o c√°c features m·ªõi t·ª´ d·ªØ li·ªáu ƒë√£ l√†m s·∫°ch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53c1ee67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üîß FEATURE ENGINEERING PIPELINE\n",
      "======================================================================\n",
      "\n",
      "üìä Basic Features:\n",
      "‚úì Created 'total_guests' = adults + children + babies\n",
      "   Range: [2.0, 2.0]\n",
      "‚úì Created 'total_nights' = weekend_nights + week_nights\n",
      "   Range: [0, 11]\n",
      "‚úì Created 'is_family' (has children/babies)\n",
      "   Family bookings: 0.00%\n",
      "\n",
      "üìä Discretization:\n",
      "‚úì Created 'lead_time_category' with 6 bins\n",
      "   Bins: [0, 7, 30, 90, 180, 365, 1000]\n",
      "   Distribution:\n",
      "     0-7days: 19,746 (16.5%)\n",
      "     7-30days: 18,960 (15.9%)\n",
      "     30-90days: 29,553 (24.8%)\n",
      "     90-180days: 26,439 (22.1%)\n",
      "     180-365days: 21,544 (18.0%)\n",
      "     365+days: 3,148 (2.6%)\n",
      "‚úì Created 'country_grouped' (top 10 + Other)\n",
      "   Top countries: ['PRT', 'GBR', 'FRA', 'ESP', 'DEU', 'ITA', 'IRL', 'BEL', 'BRA', 'NLD']\n",
      "   'Other' category: 15.16%\n",
      "‚úì Created 'adr_category' (price category)\n",
      "   Bins: [0, 50, 100, 150, 200, inf]\n",
      "\n",
      "üìä Temporal Features:\n",
      "‚úì Created seasonal features:\n",
      "   - arrival_season: ['Summer', 'Fall', 'Winter', 'Spring']\n",
      "   - is_summer: 31.4%\n",
      "   - is_peak_season: 22.2%\n",
      "‚úì Created arrival date features:\n",
      "   - arrival_date: 2015-07-01 00:00:00 to 2017-08-31 00:00:00\n",
      "   - is_weekend_arrival: 43.4%\n",
      "\n",
      "üìä Guest History Features:\n",
      "‚úì Created guest history features:\n",
      "   - has_canceled_before: 5.43%\n",
      "   - is_returning_customer: 3.85%\n",
      "   - repeated_and_canceled_before: 0.78%\n",
      "\n",
      "üìä Room Features:\n",
      "‚úì Created 'room_type_changed': 12.49% of bookings\n",
      "\n",
      "üìä Booking Features:\n",
      "‚úì Created booking features:\n",
      "   - has_special_requests: 41.10%\n",
      "   - has_booking_changes: 15.14%\n",
      "   - has_agent: 86.31%\n",
      "   - is_direct_booking: 12.27%\n",
      "   - deposit_required: 12.35%\n",
      "   - requires_parking: 6.21%\n",
      "\n",
      "üìä Revenue Features:\n",
      "‚úì Created revenue features:\n",
      "   - total_revenue: mean=344.32\n",
      "   - revenue_per_guest: mean=172.16\n",
      "\n",
      "======================================================================\n",
      "‚úÖ FEATURE ENGINEERING COMPLETE\n",
      "   Original columns: 29\n",
      "   Final columns: 56\n",
      "   New features created: 27\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Apply all feature engineering\n",
    "df_features = create_all_features(df_step3, config_path=str(config_path), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb720b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìã DANH S√ÅCH FEATURES M·ªöI:\n",
      "==================================================\n",
      "\n",
      "üîπ BASIC:\n",
      "   ‚úì total_guests\n",
      "   ‚úì total_nights\n",
      "   ‚úì is_family\n",
      "\n",
      "üîπ DISCRETIZED:\n",
      "   ‚úì lead_time_category\n",
      "   ‚úì country_grouped\n",
      "   ‚úì adr_category\n",
      "\n",
      "üîπ TEMPORAL:\n",
      "   ‚úì arrival_season\n",
      "   ‚úì arrival_month_num\n",
      "   ‚úì is_summer\n",
      "   ‚úì is_peak_season\n",
      "   ‚úì arrival_date\n",
      "   ‚úì arrival_day_of_week\n",
      "   ‚úì is_weekend_arrival\n",
      "\n",
      "üîπ GUEST_HISTORY:\n",
      "   ‚úì has_canceled_before\n",
      "   ‚úì is_returning_customer\n",
      "   ‚úì repeated_and_canceled_before\n",
      "   ‚úì total_previous_bookings\n",
      "   ‚úì cancellation_ratio\n",
      "\n",
      "üîπ ROOM:\n",
      "   ‚úì room_type_changed\n",
      "\n",
      "üîπ BOOKING:\n",
      "   ‚úì has_special_requests\n",
      "   ‚úì has_booking_changes\n",
      "   ‚úì has_agent\n",
      "   ‚úì is_direct_booking\n",
      "   ‚úì deposit_required\n",
      "   ‚úì requires_parking\n",
      "\n",
      "üîπ REVENUE:\n",
      "   ‚úì total_revenue\n",
      "   ‚úì revenue_per_guest\n"
     ]
    }
   ],
   "source": [
    "# List all new features\n",
    "feature_list = get_feature_list()\n",
    "\n",
    "print(\"\\nüìã DANH S√ÅCH FEATURES M·ªöI:\")\n",
    "print(\"=\"*50)\n",
    "for category, features in feature_list.items():\n",
    "    print(f\"\\nüîπ {category.upper()}:\")\n",
    "    for feat in features:\n",
    "        if feat in df_features.columns:\n",
    "            print(f\"   ‚úì {feat}\")\n",
    "        else:\n",
    "            print(f\"   ‚úó {feat} (not created)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2524cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick statistics of new features\n",
    "new_features = [\n",
    "    'total_guests', 'total_nights', 'is_family',\n",
    "    'is_summer', 'is_peak_season', \n",
    "    'has_canceled_before', 'is_returning_customer',\n",
    "    'room_type_changed', 'deposit_required'\n",
    "]\n",
    "\n",
    "print(\"\\nüìä TH·ªêNG K√ä FEATURES M·ªöI:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for feat in new_features:\n",
    "    if feat in df_features.columns:\n",
    "        if df_features[feat].dtype in ['int64', 'float64']:\n",
    "            if df_features[feat].nunique() <= 2:  # Binary feature\n",
    "                pct = df_features[feat].mean() * 100\n",
    "                print(f\"{feat:30s}: {pct:6.2f}% = 1\")\n",
    "            else:\n",
    "                mean = df_features[feat].mean()\n",
    "                print(f\"{feat:30s}: mean = {mean:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8ea08a",
   "metadata": {},
   "source": [
    "## 6. Th·ªëng K√™ Sau Ti·ªÅn X·ª≠ L√Ω"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "662e84d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üìä SO S√ÅNH TR∆Ø·ªöC - SAU TI·ªÄN X·ª¨ L√ù\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Before</th>\n",
       "      <th>After</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rows</td>\n",
       "      <td>119,390</td>\n",
       "      <td>119,390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Columns</td>\n",
       "      <td>32</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Missing Values</td>\n",
       "      <td>129,425</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Memory (MB)</td>\n",
       "      <td>104.83</td>\n",
       "      <td>117.17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Metric   Before    After\n",
       "0            Rows  119,390  119,390\n",
       "1         Columns       32       56\n",
       "2  Missing Values  129,425        0\n",
       "3     Memory (MB)   104.83   117.17"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Comparison: Before vs After\n",
    "print(\"=\"*70)\n",
    "print(\"üìä SO S√ÅNH TR∆Ø·ªöC - SAU TI·ªÄN X·ª¨ L√ù\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "comparison = pd.DataFrame({\n",
    "    'Metric': ['Rows', 'Columns', 'Missing Values', 'Memory (MB)'],\n",
    "    'Before': [\n",
    "        f\"{df_raw.shape[0]:,}\",\n",
    "        df_raw.shape[1],\n",
    "        f\"{df_raw.isnull().sum().sum():,}\",\n",
    "        f\"{df_raw.memory_usage(deep=True).sum() / 1024**2:.2f}\"\n",
    "    ],\n",
    "    'After': [\n",
    "        f\"{df_features.shape[0]:,}\",\n",
    "        df_features.shape[1],\n",
    "        f\"{df_features.isnull().sum().sum():,}\",\n",
    "        f\"{df_features.memory_usage(deep=True).sum() / 1024**2:.2f}\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "display(comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e05c32b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üóëÔ∏è Columns REMOVED (3):\n",
      "   - company\n",
      "   - reservation_status\n",
      "   - reservation_status_date\n",
      "\n",
      "‚ûï Columns ADDED (27):\n",
      "   + adr_category\n",
      "   + arrival_date\n",
      "   + arrival_day_of_week\n",
      "   + arrival_month_num\n",
      "   + arrival_season\n",
      "   + cancellation_ratio\n",
      "   + country_grouped\n",
      "   + deposit_required\n",
      "   + has_agent\n",
      "   + has_booking_changes\n",
      "   + has_canceled_before\n",
      "   + has_special_requests\n",
      "   + is_direct_booking\n",
      "   + is_family\n",
      "   + is_peak_season\n",
      "   + is_returning_customer\n",
      "   + is_summer\n",
      "   + is_weekend_arrival\n",
      "   + lead_time_category\n",
      "   + repeated_and_canceled_before\n",
      "   + requires_parking\n",
      "   + revenue_per_guest\n",
      "   + room_type_changed\n",
      "   + total_guests\n",
      "   + total_nights\n",
      "   + total_previous_bookings\n",
      "   + total_revenue\n"
     ]
    }
   ],
   "source": [
    "# Columns removed and added\n",
    "removed_cols = set(df_raw.columns) - set(df_features.columns)\n",
    "added_cols = set(df_features.columns) - set(df_raw.columns)\n",
    "\n",
    "print(f\"\\nüóëÔ∏è Columns REMOVED ({len(removed_cols)}):\")\n",
    "for col in sorted(removed_cols):\n",
    "    print(f\"   - {col}\")\n",
    "\n",
    "print(f\"\\n‚ûï Columns ADDED ({len(added_cols)}):\")\n",
    "for col in sorted(added_cols):\n",
    "    print(f\"   + {col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ccb8cb",
   "metadata": {},
   "source": [
    "## 7. Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a000ac14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Features shape: (119390, 55)\n",
      "üéØ Target shape: (119390,)\n",
      "\n",
      "üéØ Target distribution:\n",
      "is_canceled\n",
      "0    75166\n",
      "1    44224\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Separate features and target\n",
    "X = df_features.drop(columns=[TARGET])\n",
    "y = df_features[TARGET]\n",
    "\n",
    "print(f\"üìä Features shape: {X.shape}\")\n",
    "print(f\"üéØ Target shape: {y.shape}\")\n",
    "print(f\"\\nüéØ Target distribution:\")\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a8a3221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä TRAIN/TEST SPLIT (Stratified)\n",
      "==================================================\n",
      "\n",
      "üîπ Training Set:\n",
      "   X_train: (95512, 55)\n",
      "   y_train: (95512,)\n",
      "   Canceled ratio: 37.04%\n",
      "\n",
      "üîπ Test Set:\n",
      "   X_test: (23878, 55)\n",
      "   y_test: (23878,)\n",
      "   Canceled ratio: 37.04%\n"
     ]
    }
   ],
   "source": [
    "# Train/Test split with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=TEST_SIZE,\n",
    "    random_state=SEED,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(f\"üìä TRAIN/TEST SPLIT (Stratified)\")\n",
    "print(\"=\"*50)\n",
    "print(f\"\\nüîπ Training Set:\")\n",
    "print(f\"   X_train: {X_train.shape}\")\n",
    "print(f\"   y_train: {y_train.shape}\")\n",
    "print(f\"   Canceled ratio: {y_train.mean()*100:.2f}%\")\n",
    "\n",
    "print(f\"\\nüîπ Test Set:\")\n",
    "print(f\"   X_test: {X_test.shape}\")\n",
    "print(f\"   y_test: {y_test.shape}\")\n",
    "print(f\"   Canceled ratio: {y_test.mean()*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3639c921",
   "metadata": {},
   "source": [
    "## 8. X·ª≠ L√Ω Imbalance (SMOTE)\n",
    "\n",
    "Dataset c√≥ t·ª∑ l·ªá hu·ª∑ ~37%, kh√¥ng qu√° nghi√™m tr·ªçng nh∆∞ng v·∫´n n√™n x·ª≠ l√Ω."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5051d080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ SMOTE is available\n"
     ]
    }
   ],
   "source": [
    "# Try to import SMOTE\n",
    "try:\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    SMOTE_AVAILABLE = True\n",
    "    print(\"‚úÖ SMOTE is available\")\n",
    "except ImportError:\n",
    "    SMOTE_AVAILABLE = False\n",
    "    print(\"‚ö†Ô∏è imbalanced-learn not installed. Run: pip install imbalanced-learn\")\n",
    "    print(\"   Skipping SMOTE. Will use class_weight instead.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f18fc03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Numerical columns: 40\n",
      "üìä Categorical columns: 14\n",
      "\n",
      "‚ö†Ô∏è Categorical columns found: ['hotel', 'arrival_date_month', 'meal', 'country', 'market_segment']...\n",
      "   Need to encode before SMOTE\n"
     ]
    }
   ],
   "source": [
    "# Select only numerical columns for SMOTE\n",
    "# SMOTE requires numerical data\n",
    "numerical_cols = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_cols = X_train.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "print(f\"üìä Numerical columns: {len(numerical_cols)}\")\n",
    "print(f\"üìä Categorical columns: {len(categorical_cols)}\")\n",
    "\n",
    "if categorical_cols:\n",
    "    print(f\"\\n‚ö†Ô∏è Categorical columns found: {categorical_cols[:5]}...\")\n",
    "    print(\"   Need to encode before SMOTE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce1b5d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Encoded shapes:\n",
      "   X_train_encoded: (95512, 286)\n",
      "   X_test_encoded: (23878, 286)\n"
     ]
    }
   ],
   "source": [
    "# Encode categorical for SMOTE (if any)\n",
    "if categorical_cols:\n",
    "    # One-hot encode categorical columns\n",
    "    X_train_encoded = pd.get_dummies(X_train, columns=categorical_cols, drop_first=True)\n",
    "    X_test_encoded = pd.get_dummies(X_test, columns=categorical_cols, drop_first=True)\n",
    "    \n",
    "    # Align columns (ensure same columns in train and test)\n",
    "    missing_cols = set(X_train_encoded.columns) - set(X_test_encoded.columns)\n",
    "    for col in missing_cols:\n",
    "        X_test_encoded[col] = 0\n",
    "    \n",
    "    extra_cols = set(X_test_encoded.columns) - set(X_train_encoded.columns)\n",
    "    X_test_encoded = X_test_encoded.drop(columns=list(extra_cols))\n",
    "    \n",
    "    # Ensure same column order\n",
    "    X_test_encoded = X_test_encoded[X_train_encoded.columns]\n",
    "    \n",
    "    print(f\"‚úÖ Encoded shapes:\")\n",
    "    print(f\"   X_train_encoded: {X_train_encoded.shape}\")\n",
    "    print(f\"   X_test_encoded: {X_test_encoded.shape}\")\n",
    "else:\n",
    "    X_train_encoded = X_train\n",
    "    X_test_encoded = X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02a1eaa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Applying SMOTE...\n",
      "--------------------------------------------------\n",
      "\n",
      "üìä Before SMOTE:\n",
      "   X_train: (95512, 40)\n",
      "   Class 0: 60,133\n",
      "   Class 1: 35,379\n",
      "\n",
      "üìä After SMOTE:\n",
      "   X_train_resampled: (120266, 40)\n",
      "   Class 0: 60,133\n",
      "   Class 1: 60,133\n"
     ]
    }
   ],
   "source": [
    "# Apply SMOTE if available\n",
    "if SMOTE_AVAILABLE:\n",
    "    print(\"üîÑ Applying SMOTE...\")\n",
    "    print(\"-\"*50)\n",
    "    \n",
    "    # Drop non-numeric columns for SMOTE\n",
    "    X_train_numeric = X_train_encoded.select_dtypes(include=[np.number])\n",
    "    \n",
    "    # Handle any remaining missing values\n",
    "    X_train_numeric = X_train_numeric.fillna(X_train_numeric.median())\n",
    "    \n",
    "    smote = SMOTE(random_state=SEED)\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train_numeric, y_train)\n",
    "    \n",
    "    print(f\"\\nüìä Before SMOTE:\")\n",
    "    print(f\"   X_train: {X_train_numeric.shape}\")\n",
    "    print(f\"   Class 0: {(y_train == 0).sum():,}\")\n",
    "    print(f\"   Class 1: {(y_train == 1).sum():,}\")\n",
    "    \n",
    "    print(f\"\\nüìä After SMOTE:\")\n",
    "    print(f\"   X_train_resampled: {X_train_resampled.shape}\")\n",
    "    print(f\"   Class 0: {(y_train_resampled == 0).sum():,}\")\n",
    "    print(f\"   Class 1: {(y_train_resampled == 1).sum():,}\")\n",
    "else:\n",
    "    X_train_resampled = X_train_encoded.select_dtypes(include=[np.number])\n",
    "    y_train_resampled = y_train\n",
    "    print(\"‚ö†Ô∏è SMOTE skipped. Using original data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b83eb1",
   "metadata": {},
   "source": [
    "## 9. Chu·∫©n B·ªã Data cho Association Rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "90869a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Prepared data for association rules:\n",
      "   - Input columns: 11\n",
      "   - Output features: 47\n",
      "   - Rows: 119390\n",
      "\n",
      "üìä Association Rules Data:\n",
      "   Shape: (119390, 47)\n",
      "   Sample columns: ['is_family', 'is_returning_customer', 'hotel=City Hotel', 'hotel=Resort Hotel', 'arrival_season=Fall', 'arrival_season=Spring', 'arrival_season=Summer', 'arrival_season=Winter', 'meal=BB', 'meal=FB']\n"
     ]
    }
   ],
   "source": [
    "# Prepare data for association rules\n",
    "df_association = prepare_for_association_rules(df_features, verbose=True)\n",
    "\n",
    "print(f\"\\nüìä Association Rules Data:\")\n",
    "print(f\"   Shape: {df_association.shape}\")\n",
    "print(f\"   Sample columns: {list(df_association.columns)[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e771970",
   "metadata": {},
   "source": [
    "## 10. L∆∞u D·ªØ Li·ªáu ƒê√£ X·ª≠ L√Ω"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "55e5ebaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Saving processed data to: c:\\Coding\\DataMining\\Nhom12_BaiTapLon_DataMining\\data\\processed\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Create processed data directory\n",
    "processed_dir = project_root / 'data' / 'processed'\n",
    "processed_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"üìÅ Saving processed data to: {processed_dir}\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff6efdc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved: hotel_bookings_processed.csv ((119390, 56))\n",
      "‚úÖ Saved: train.csv ((95512, 56))\n",
      "‚úÖ Saved: test.csv ((23878, 56))\n",
      "‚úÖ Saved: X_train_encoded.csv ((95512, 286))\n",
      "‚úÖ Saved: y_train.csv ((95512,))\n",
      "‚úÖ Saved: X_test_encoded.csv ((23878, 286))\n",
      "‚úÖ Saved: y_test.csv ((23878,))\n",
      "‚úÖ Saved: X_train_resampled.csv ((120266, 40))\n",
      "‚úÖ Saved: y_train_resampled.csv (120266,)\n",
      "‚úÖ Saved: association_rules_data.csv ((119390, 47))\n"
     ]
    }
   ],
   "source": [
    "# Save all datasets\n",
    "\n",
    "# 1. Full processed data (with features, before encoding)\n",
    "df_features.to_csv(processed_dir / 'hotel_bookings_processed.csv', index=False)\n",
    "print(f\"‚úÖ Saved: hotel_bookings_processed.csv ({df_features.shape})\")\n",
    "\n",
    "# 2. Train set (original)\n",
    "train_df = pd.concat([X_train, y_train], axis=1)\n",
    "train_df.to_csv(processed_dir / 'train.csv', index=False)\n",
    "print(f\"‚úÖ Saved: train.csv ({train_df.shape})\")\n",
    "\n",
    "# 3. Test set (original)\n",
    "test_df = pd.concat([X_test, y_test], axis=1)\n",
    "test_df.to_csv(processed_dir / 'test.csv', index=False)\n",
    "print(f\"‚úÖ Saved: test.csv ({test_df.shape})\")\n",
    "\n",
    "# 4. Train set encoded (for modeling)\n",
    "X_train_encoded.to_csv(processed_dir / 'X_train_encoded.csv', index=False)\n",
    "y_train.to_csv(processed_dir / 'y_train.csv', index=False)\n",
    "print(f\"‚úÖ Saved: X_train_encoded.csv ({X_train_encoded.shape})\")\n",
    "print(f\"‚úÖ Saved: y_train.csv ({y_train.shape})\")\n",
    "\n",
    "# 5. Test set encoded (for modeling)\n",
    "X_test_encoded.to_csv(processed_dir / 'X_test_encoded.csv', index=False)\n",
    "y_test.to_csv(processed_dir / 'y_test.csv', index=False)\n",
    "print(f\"‚úÖ Saved: X_test_encoded.csv ({X_test_encoded.shape})\")\n",
    "print(f\"‚úÖ Saved: y_test.csv ({y_test.shape})\")\n",
    "\n",
    "# 6. Resampled training data (if SMOTE was applied)\n",
    "if SMOTE_AVAILABLE:\n",
    "    X_train_resampled.to_csv(processed_dir / 'X_train_resampled.csv', index=False)\n",
    "    pd.Series(y_train_resampled, name=TARGET).to_csv(processed_dir / 'y_train_resampled.csv', index=False)\n",
    "    print(f\"‚úÖ Saved: X_train_resampled.csv ({X_train_resampled.shape})\")\n",
    "    print(f\"‚úÖ Saved: y_train_resampled.csv ({len(y_train_resampled)},)\")\n",
    "\n",
    "# 7. Association rules data\n",
    "df_association.to_csv(processed_dir / 'association_rules_data.csv', index=False)\n",
    "print(f\"‚úÖ Saved: association_rules_data.csv ({df_association.shape})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc87cb56",
   "metadata": {},
   "source": [
    "## 11. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c5ef535a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üìù SUMMARY - TI·ªÄN X·ª¨ L√ù & FEATURE ENGINEERING\n",
      "======================================================================\n",
      "\n",
      "‚úÖ TI·ªÄN X·ª¨ L√ù HO√ÄN TH√ÄNH:\n",
      "   1. Lo·∫°i b·ªè Data Leakage columns: ['reservation_status', 'reservation_status_date']\n",
      "   2. X·ª≠ l√Ω Missing values: 129,425 ‚Üí 0\n",
      "   3. X·ª≠ l√Ω Outliers: IQR method v·ªõi capping\n",
      "\n",
      "‚úÖ FEATURE ENGINEERING:\n",
      "   - Columns ban ƒë·∫ßu: 32\n",
      "   - Columns sau x·ª≠ l√Ω: 56\n",
      "   - Features m·ªõi: 27\n",
      "\n",
      "‚úÖ TRAIN/TEST SPLIT:\n",
      "   - Train: 95,512 samples (80%)\n",
      "   - Test: 23,878 samples (20%)\n",
      "\n",
      "‚úÖ SMOTE RESAMPLING:\n",
      "   - Before: 95,512 samples\n",
      "   - After: 120,266 samples\n",
      "\n",
      "‚úÖ FILES ƒê√É L∆ØU:\n",
      "   - association_rules_data.csv: 31.19 MB\n",
      "   - hotel_bookings_processed.csv: 25.01 MB\n",
      "   - test.csv: 5.00 MB\n",
      "   - train.csv: 20.01 MB\n",
      "   - X_test_encoded.csv: 31.08 MB\n",
      "   - X_train_encoded.csv: 143.99 MB\n",
      "   - X_train_resampled.csv: 12.95 MB\n",
      "   - y_test.csv: 0.07 MB\n",
      "   - y_train.csv: 0.27 MB\n",
      "   - y_train_resampled.csv: 0.34 MB\n",
      "\n",
      "======================================================================\n",
      "üéâ NOTEBOOK HO√ÄN TH√ÄNH!\n",
      "   Ti·∫øp theo: 03_mining_or_clustering.ipynb\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìù SUMMARY - TI·ªÄN X·ª¨ L√ù & FEATURE ENGINEERING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n‚úÖ TI·ªÄN X·ª¨ L√ù HO√ÄN TH√ÄNH:\")\n",
    "print(f\"   1. Lo·∫°i b·ªè Data Leakage columns: {list(removed_cols & set(leakage_cols))}\")\n",
    "print(f\"   2. X·ª≠ l√Ω Missing values: {missing_total:,} ‚Üí 0\")\n",
    "print(f\"   3. X·ª≠ l√Ω Outliers: IQR method v·ªõi capping\")\n",
    "\n",
    "print(f\"\\n‚úÖ FEATURE ENGINEERING:\")\n",
    "print(f\"   - Columns ban ƒë·∫ßu: {df_raw.shape[1]}\")\n",
    "print(f\"   - Columns sau x·ª≠ l√Ω: {df_features.shape[1]}\")\n",
    "print(f\"   - Features m·ªõi: {len(added_cols)}\")\n",
    "\n",
    "print(f\"\\n‚úÖ TRAIN/TEST SPLIT:\")\n",
    "print(f\"   - Train: {len(y_train):,} samples ({(1-TEST_SIZE)*100:.0f}%)\")\n",
    "print(f\"   - Test: {len(y_test):,} samples ({TEST_SIZE*100:.0f}%)\")\n",
    "\n",
    "if SMOTE_AVAILABLE:\n",
    "    print(f\"\\n‚úÖ SMOTE RESAMPLING:\")\n",
    "    print(f\"   - Before: {len(y_train):,} samples\")\n",
    "    print(f\"   - After: {len(y_train_resampled):,} samples\")\n",
    "\n",
    "print(f\"\\n‚úÖ FILES ƒê√É L∆ØU:\")\n",
    "for f in processed_dir.glob('*.csv'):\n",
    "    size_mb = f.stat().st_size / 1024**2\n",
    "    print(f\"   - {f.name}: {size_mb:.2f} MB\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üéâ NOTEBOOK HO√ÄN TH√ÄNH!\")\n",
    "print(\"   Ti·∫øp theo: 03_mining_or_clustering.ipynb\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
